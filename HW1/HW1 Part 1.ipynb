{"cells":[{"cell_type":"markdown","metadata":{"id":"nFqIMlX0hG73"},"source":["# HW 1 Part 1: Preprocessing the Credit Approval Dataset\n","\n","Perform the following tasks on the credit approval dataset (crx.data contains the dataset and crx.names contains the description of the dataset). High pass and low pass specifications are on Canvas. Please note that ALL questions labelled [LP] must be completed satisfactorily to receive a low pass on the assignment. The [HP] question specifications combine all parts of the homework. Please refer to Canvas for more details.\n","\n","Note that if you are unable to complete any of the LP questions satisfactorily, you will receive a grade of \"revision required\". You can revise and resubmit your work in exchange for a token. Please review the syllabus for more information on specifications grading.\n","\n","**VERY IMPORTANT**: Include **ALL** the references you used for this assignment, including names of classmates you discuss with. Failure to cite your sources counts as an act of academic dishonesty and will be taken seriously without zero tolerance. You will automatically receive a “fail” grade in the homework and further serious penalties may be imposed.\n","\n","NOTE: You can look for help on the Internet but refrain from referencing too much. Please cite all your sources in your submission. \n","When you submit your assignment, you automatically agree to the following statement. If you do not agree, it is your responsibility to provide the reason.\n","\n","“*I affirm that I have neither given nor received unauthorized help in completing this homework. I am not aware of others receiving such help. I have cited all the sources in the solution file.*”"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"WZyc-1p4Dc-y"},"outputs":[],"source":["## Your code goes here. Import the csv into a pandas dataframe here\n","import pandas as pd\n","\n","df = pd.read_csv('./crx.data', header=None, na_values=\"?\")\n"]},{"cell_type":"markdown","metadata":{"id":"m6ElwLnzjL0a"},"source":["[LP 1] Deal with the missing values in the credit analysis dataset. Explain what you did with the following columns:\n","\n","1. Column A1 (at index 0) \n","2. Column A2 (at index 1)\n","3. Column A4 (at index 3)\n","4. Column A5 (at index 4)\n","5. Column A6 (at index 5)\n","6. Column A7 (at index 6)\n","7. Column A14 (at index 13)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Following the class activities performed in class on the credit approval dataset, the names file gives us a list of attributes with missing values. In class we dealt with the missing values using a pandas function parameter. When we read the data into a DataFrame, we can set na_values = \"?\", so that when pandas is reading the data, it treats the ? as a missing value. After missing values are read correctly, we can now take a look at each one the columns below to deal with the missing values. \n","\n","For attributes with categorical data, we can look at the more frequently occuring category aka mode and replace the null values with the mode. \n","\n","For attributes with numerical data, we can look at the mean value of the given attribute and replace null values with the mean. \n","\n","\n","\n","1. Column A1, is categorical a,b data with top category being b\n","2. Column A2, has 12 \"?\" missing values\n","3. Column A4, \n","4. Column A5, \n","5. Column A6, \n","6. Column A7, \n","7. Column A14,"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DMY-ZEKcDfC7"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 690 entries, 0 to 689\n","Data columns (total 16 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   0       678 non-null    object \n"," 1   1       678 non-null    float64\n"," 2   2       690 non-null    float64\n"," 3   3       684 non-null    object \n"," 4   4       684 non-null    object \n"," 5   5       681 non-null    object \n"," 6   6       681 non-null    object \n"," 7   7       690 non-null    float64\n"," 8   8       690 non-null    object \n"," 9   9       690 non-null    object \n"," 10  10      690 non-null    int64  \n"," 11  11      690 non-null    object \n"," 12  12      690 non-null    object \n"," 13  13      677 non-null    float64\n"," 14  14      690 non-null    int64  \n"," 15  15      690 non-null    object \n","dtypes: float64(4), int64(2), object(10)\n","memory usage: 86.4+ KB\n"]},{"data":{"text/plain":["count    678.000000\n","mean      31.568171\n","std       11.957862\n","min       13.750000\n","25%       22.602500\n","50%       28.460000\n","75%       38.230000\n","max       80.250000\n","Name: 1, dtype: float64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["## Your code for LP 1 goes here.\n","df.info()\n","df[1].describe() \n"]},{"cell_type":"markdown","metadata":{"id":"xh9UM5hqn1HO"},"source":["\n","[LP 2] Use encoders and convert the categorical variables to numerical values: Columns A1, A4, A5, A6, A7, A9, A10, A12, A13\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-T1QCICvDiDz"},"outputs":[],"source":["## Your code for LP 2 goes here. "]},{"cell_type":"markdown","metadata":{"id":"zJwoqyaFDFlt"},"source":["[HP 1] Describe your choices to preprocess these columns and explain why they are appropriate for the column."]},{"cell_type":"markdown","metadata":{"id":"qK5itr7pDnCJ"},"source":["< Your answer for HP 1 goes here >"]},{"cell_type":"markdown","metadata":{"id":"eYIkt1kNn4AQ"},"source":["[LP 3] Use an appropriate scaler to scale the numerical values to a suitable range of values. Briefly explain the process you used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uY1xpzTmDpBr"},"outputs":[],"source":["## Your code for LP 3 goes here. "]},{"cell_type":"markdown","metadata":{"id":"UWT5NohBoJjV"},"source":["Save your clean dataset in a file called **crx_clean.data**. Submit this file along with the ipynb solution file. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49nC0392n5cG"},"outputs":[],"source":["## Your code to save the dataframe to a csv file goes here."]},{"cell_type":"markdown","metadata":{"id":"VQYb_dd3obyT"},"source":["# References\n","Include ALL your references here. \n","https://pandas.pydata.org/docs/user_guide/index.html#user-guide\n","\n","# What to turn in:\n","1. The ipynb solution file, which includes the references\n","2. If you use Colab or GitHub for version control, please share a link to your notebook or GitHub repository\n","3. The crx_clean.data file\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"58a1eea73685d3c23826b766191cfb54a6b6d10ac1a683ca7853de5905ce1a11"}}},"nbformat":4,"nbformat_minor":0}
