{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# HW 3: Supervised Learning on the Bank Marketing Dataset\n","\n","The original dataset is available here: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n","We have a modified subset of this dataset to practice data  preprocessing. \n","\n","Perform the following tasks on the provided clean bank marketing dataset before encoding and scaling (bank-hw1.csv contains the dataset and bank-names.txt contains the description of the original dataset). \n","* Complete all the [LP] questions to receive a \"low pass\" grade on the homework. \n","* Complete all the [LP] questions and [HP 1] and [HP 2] to receive a \"high pass\" grade on the homework. \n","* Passing the question marked [HP+] is not required to receive a \"high pass\" grade. However, it is necessary for an A+ in the course.\n","\n","Note that if you are unable to complete any of the LP questions satisfactorily, you will receive a grade of \"revision required\". You can revise and resubmit your work in exchange for a token. Please review the syllabus for more information on specifications grading.\n","\n","**VERY IMPORTANT**: Include **ALL** the references you used for this assignment, including names of classmates you discuss with. Failure to cite your sources counts as an act of academic dishonesty and will be taken seriously without zero tolerance. You will automatically receive a “fail” grade in the homework and further serious penalties may be imposed.\n","\n","NOTE: You can look for help on the Internet but refrain from referencing too much. Please cite all your sources in your submission. \n","When you submit your assignment, you automatically agree to the following statement. If you do not agree, it is your responsibility to provide the reason.\n","\n","“*I affirm that I have neither given nor received unauthorized help in completing this homework. I am not aware of others receiving such help. I have cited all the sources in the solution file.*”"],"metadata":{"id":"7Cd_pe4uWiOS"}},{"cell_type":"markdown","source":["[LP 1] Import the provided clean data file, your preprocessed dataset from HW1, or clean the dataset here. Extract the following columns:\n","\n","1. duration: all entries must be non-negative\n","2. campaign\n","3. pdays\n","4. previous\n","\n","The set of values in each column and their meaning is provided in the bank-names.txt file. You can use the information to make decisions. Please explain your choices if you are preprocessing the dataset again here OR comment that you are using your preprocessed dataset from HW1. \n","\n","**Q1. How do you figure out if the dataset is imbalanced?**\n","\n","First, make sure you have a balanced dataset to work with. A balanced dataset is one where there are an equal number of positive and negative samples. Find if the bank marketing dataset is imbalanced. \n","\n","\n","**Q2. Balance this dataset.**\n","You are recommended to use a Random [Undersampler](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html). Sample code is provided below. "],"metadata":{"id":"FNycoKnlZOCf"}},{"cell_type":"code","source":["import pandas as pd\n","##Replace path with your file location\n","path = '/content/bank-hw2-clean.csv'\n","bank = pd.read_csv(path) \n","X = bank.values\n","y = bank[[\"y\"]]"],"metadata":{"id":"dZKEehLjYMxM","executionInfo":{"status":"ok","timestamp":1669407186685,"user_tz":480,"elapsed":173,"user":{"displayName":"Mahima Agumbe Suresh","userId":"18299594194519975712"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler\n","undersample = RandomUnderSampler(sampling_strategy='majority')\n","X_under, y_under = undersample.fit_resample(X, y)"],"metadata":{"id":"BBT3d_7IYtQ6","executionInfo":{"status":"ok","timestamp":1669407192002,"user_tz":480,"elapsed":145,"user":{"displayName":"Mahima Agumbe Suresh","userId":"18299594194519975712"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Your code for LP1 goes here\n","# Feel free to add cells below this for LP1"],"metadata":{"id":"7mTSEo9-WrIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[HP+] Comment on why the undersampler might be okay for this dataset. If not, feel free to choose a different technique and discuss the reason why you choose it. "],"metadata":{"id":"tCX8rKQ1Z3Fj"}},{"cell_type":"markdown","source":["<Your answer for HP+ goes here>"],"metadata":{"id":"_-Y-T0IVaAYn"}},{"cell_type":"markdown","source":["[LP 2] Prepare the data by splitting into training and test datasets to perform supervised learning on this filtered dataset. "],"metadata":{"id":"PHE3C7K-Xk4Z"}},{"cell_type":"code","source":["# Your code for LP2 goes here\n","# Feel free to add cells below this for LP2"],"metadata":{"id":"2mossVbUbt6z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[LP 3] Build a decision tree on the training dataset upto a maximum depth of 3 with the entropy as the criterion and plot the decision tree. Plot the decision tree. Feel free use the example code from the class on the Iris dataset. "],"metadata":{"id":"BMVdgyBiblFg"}},{"cell_type":"code","source":["# Your code for LP3 goes here\n","# Feel free to add cells below this for LP3"],"metadata":{"id":"E3Mgax-OXp5T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[HP 1] Are there any leaf nodes with an entropy > 0? If so, what does it mean? How does this model perform on the test dataset? Provide an example on how the results for a single sample can be interpreted."],"metadata":{"id":"k-LXSIMuaIqI"}},{"cell_type":"code","source":["# Your code for HP1 goes here\n","# Feel free to add cells below this for HP1"],"metadata":{"id":"Gl7LjuEwY1sy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["< Your answer for HP1 goes here >"],"metadata":{"id":"c5LLVcoaNSmD"}},{"cell_type":"markdown","source":["[LP 4] Perform grid search with cross-validation to determine the best decision tree for the dataset and decide between the following hyperparamters:\n","  min_samples_split = [4, 10, 20]\n","  max_depth = [3, 4, 5]\n","Plot the best performing model."],"metadata":{"id":"Tcgkb1cVb44n"}},{"cell_type":"code","source":["# Your code for LP4 goes here\n","# Feel free to add cells below this for LP4"],"metadata":{"id":"5dE5r-Rdcgkt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[HP 2] Interpret the results of grid search CV for the decision tree and comment on the following:\n","1. How does the model perform on the test dataset? \n","2. Based on the confusion matrix for the best performing model, do you think the model performs satisfactorily for the application?\n"],"metadata":{"id":"f79liZLlOkWf"}},{"cell_type":"code","source":["# Your code for HP2 goes here\n","# Feel free to add cells below this for HP2"],"metadata":{"id":"BL3P0vGxPbCv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["< Your answer for HP2 goes here >"],"metadata":{"id":"8ESy_f68ciUo"}},{"cell_type":"markdown","source":["# References\n","Include ALL your references here. \n","\n","# What to turn in:\n","1. The ipynb solution file, which includes the references\n","2. If you use Colab or GitHub for version control, please share a link to your notebook or GitHub repository"],"metadata":{"id":"OsHDpghuc5RT"}}]}